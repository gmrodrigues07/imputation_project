{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eccfd9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_csv(\"../data/raw/WineQT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbdd7e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "Id                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aed6c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 13 columns.\n",
      "There are 0 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Values, % of Total Values]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_values(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    \n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns\n",
    "    \n",
    "missing_values_table = missing_values(data)\n",
    "missing_values_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7721973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno # For visualizing missing data patterns\n",
    "\n",
    "# To see how the data correlate with each other;\n",
    "\n",
    "sorted_data = data.sort_values('oldpeak')\n",
    "msno.matrix(sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ba067",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26eb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder # For converting categorical data to numerical values\n",
    "from sklearn.model_selection import train_test_split # For splitting data into training and testing sets\n",
    "from sklearn.metrics import accuracy_score, f1_score # For calculating accuracy and F1-score\n",
    "from sklearn.impute import KNNImputer # For imputing missing values using K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier # K-Nearest Neighbors classification model\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression # Linear regression and logistic regression models\n",
    "from sklearn.preprocessing import StandardScaler # For scaling features\n",
    "from sklearn.ensemble import RandomForestRegressor # Random Forest regression model\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest classifier model\n",
    "from sklearn.metrics import mean_squared_error # Performance metric for regression models\n",
    "from sklearn.impute import SimpleImputer # For imputing missing values with a simple strategy\n",
    "from sklearn.experimental import enable_iterative_imputer # Enable IterativeImputer (needed for MICE/MissForest)\n",
    "from sklearn.impute import IterativeImputer # IterativeImputer for MICE and MissForest\n",
    "\n",
    "from xgboost import XGBClassifier # XGBoost classification model\n",
    "from xgboost import XGBRegressor # XGBoost regression model \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import imputation techniques from imputation_techniques.py\n",
    "from imputation_techniques import impute_knn, impute_missForest, impute_mice, pool_mice_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \"\"\"\n",
    "    Reads the 'Heart disease' dataset,\n",
    "    performs some editing, and returns it.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"../data/raw/heart_disease_uci.csv\")\n",
    "    #df['num'] = df['num'].replace({2: 1, 3: 1, 4: 1})\n",
    "    df = df.drop('id', axis=1)\n",
    "    df[df.select_dtypes(['object']).columns] = df.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "    \n",
    "    categorical_columns = df.select_dtypes(include=['category']).columns\n",
    "\n",
    "    # Convert categorical to numerical\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    for column in categorical_columns:\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "    return df\n",
    "\n",
    "def split_dataset(df):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test: Training and testing sets for features and labels.\n",
    "    \"\"\"\n",
    "    X = df.drop('num', axis=1)\n",
    "    y = df['num']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # print(f'Size of the Train: {X_train.shape[0]}')\n",
    "    # print(f'Size of the Test: {X_test.shape[0]}')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_model_XGBoost(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost model on the given training set and evaluates it on the test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train, X_test, y_train, y_test: Training and testing sets for features and labels.\n",
    "    \"\"\"\n",
    "    # Create and train the XGBoost model\n",
    "    xgb_model = XGBClassifier()\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\\n\")\n",
    "    return accuracy, f1\n",
    "    \n",
    "def train_model_random_forest(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Creates and trains a RandomForest model on the given training set \n",
    "    and evaluates its performance on the test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train, X_test, y_train, y_test: Training and testing sets for features and labels.\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy, f1_score (float): Accuracy and F1-Score of the trained model on the test set.\n",
    "    \"\"\"\n",
    "    # Create and train the RandomForest model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\\n\")\n",
    "    return accuracy, f1\n",
    "\n",
    "def train_model_logistic(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Creates and trains a LogisticRegression model on the given training set \n",
    "    and evaluates its performance on the test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train, X_test, y_train, y_test: Training and testing sets for features and labels.\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy, f1_score (float): Accuracy and F1-Score of the trained model on the test set.\n",
    "    \"\"\"\n",
    "    # Scale features for LogisticRegression convergence\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Create and train the LogisticRegression model\n",
    "    lr_model = LogisticRegression(max_iter=50000)\n",
    "    lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = lr_model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\\n\")\n",
    "    return accuracy, f1\n",
    "\n",
    "# To compare the success of the methods\n",
    "accuracies = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# READ AND SPLIT DATA ONCE - ALL METHODS WILL USE THIS SAME SPLIT\n",
    "\n",
    "print(\"Loading and splitting data once for all methods...\")\n",
    "\n",
    "df_original = read_data()\n",
    "X_train_original, X_test_original, y_train_original, y_test_original = split_dataset(df_original)\n",
    "print(f\"Train size: {X_train_original.shape[0]}, Test size: {X_test_original.shape[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check class balance\n",
    "print(\"\\nClass Distribution (Target Variable 'num'):\")\n",
    "print(y_train_original.value_counts(normalize=True))\n",
    "print(\"\\nNote: Imbalanced classes can lead to lower accuracy!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 1: No Handling (use original split with missing values)\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 1: No Handling\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train = X_train_original.copy()\n",
    "X_test = X_test_original.copy()\n",
    "y_train = y_train_original.copy()\n",
    "y_test = y_test_original.copy()\n",
    "\n",
    "# Train an XGBoost model on the dataset without handling missing values\n",
    "accuracy_no_handling, f1_no_handling = train_model_XGBoost(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Store the accuracy and F1-score in dictionaries\n",
    "accuracies['No Handling'] = accuracy_no_handling\n",
    "f1_scores['No Handling'] = f1_no_handling\n",
    "\n",
    "# Show a specific row example (no imputation done in this method)\n",
    "#print(\"\\n------------------\\n\")\n",
    "#print(\"\\nExample row with missing values: \\n\")\n",
    "#print(X_train[(X_train['age']==58.0) & (X_train['sex']==1.0) & (X_train['dataset']==3.0) & (X_train['chol']==385)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2: Pairwise Deletions (drop rows with ANY missing values)\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 2: Pairwise Deletions\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train = X_train_original.copy()\n",
    "X_test = X_test_original.copy()\n",
    "y_train = y_train_original.copy()\n",
    "y_test = y_test_original.copy()\n",
    "\n",
    "# Drop rows with any missing values\n",
    "train_mask = X_train.notna().all(axis=1)\n",
    "X_train = X_train[train_mask]\n",
    "y_train = y_train[train_mask]\n",
    "\n",
    "test_mask = X_test.notna().all(axis=1)\n",
    "X_test = X_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "print(f\"After deletion - Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n",
    "\n",
    "# Train both Random Forest and Logistic Regression models\n",
    "print(\"\\nXGBoost:\")\n",
    "accuracy_pairwise_xgb, f1_pairwise_xgb = train_model_XGBoost(X_train, X_test, y_train, y_test)\n",
    "print(\"\\nRandom Forest:\")\n",
    "accuracy_pairwise_rf, f1_pairwise_rf = train_model_random_forest(X_train, X_test, y_train, y_test)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "accuracy_pairwise_lr, f1_pairwise_lr = train_model_logistic(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Store the accuracies and F1-scores\n",
    "accuracies['Pairwise_XGB'] = accuracy_pairwise_xgb\n",
    "accuracies['Pairwise_RF'] = accuracy_pairwise_rf\n",
    "accuracies['Pairwise_LR'] = accuracy_pairwise_lr\n",
    "\n",
    "f1_scores['Pairwise_XGB'] = f1_pairwise_xgb\n",
    "f1_scores['Pairwise_LR'] = f1_pairwise_lr\n",
    "f1_scores['Pairwise_RF'] = f1_pairwise_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e85b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 3: Listwise Deletions (drop rows with missing values in specific columns)\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 3: Listwise Deletions\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train = X_train_original.copy()\n",
    "X_test = X_test_original.copy()\n",
    "y_train = y_train_original.copy()\n",
    "y_test = y_test_original.copy()\n",
    "\n",
    "# Drop rows with missing values in specific columns\n",
    "cols_to_check = ['trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
    "train_mask = X_train[cols_to_check].notna().all(axis=1)\n",
    "X_train = X_train[train_mask]\n",
    "y_train = y_train[train_mask]\n",
    "\n",
    "test_mask = X_test[cols_to_check].notna().all(axis=1)\n",
    "X_test = X_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "print(f\"After deletion - Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n",
    "\n",
    "# Train both Random Forest and Logistic Regression models\n",
    "print(\"\\nXGBoost:\")\n",
    "accuracy_listwise_xgb, f1_listwise_xgb = train_model_XGBoost(X_train, X_test, y_train, y_test)\n",
    "print(\"\\nRandom Forest:\")\n",
    "accuracy_listwise_rf, f1_listwise_rf = train_model_random_forest(X_train, X_test, y_train, y_test)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "accuracy_listwise_lr, f1_listwise_lr = train_model_logistic(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Store the accuracies and F1-scores\n",
    "accuracies['Listwise_XGB'] = accuracy_listwise_xgb\n",
    "accuracies['Listwise_RF'] = accuracy_listwise_rf\n",
    "accuracies['Listwise_LR'] = accuracy_listwise_lr\n",
    "\n",
    "f1_scores['Listwise_XGB'] = f1_listwise_xgb\n",
    "f1_scores['Listwise_LR'] = f1_listwise_lr\n",
    "f1_scores['Listwise_RF'] = f1_listwise_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dff8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 4: Dropping Entire Columns (drop columns with ANY missing values)\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD 4: Dropping Entire Columns\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train = X_train_original.copy()\n",
    "X_test = X_test_original.copy()\n",
    "y_train = y_train_original.copy()\n",
    "y_test = y_test_original.copy()\n",
    "\n",
    "# Drop entire columns with any missing values\n",
    "cols_with_missing = X_train.columns[X_train.isna().any()].tolist()\n",
    "print(f\"Dropping columns: {cols_with_missing}\")\n",
    "X_train = X_train.drop(columns=cols_with_missing)\n",
    "X_test = X_test.drop(columns=cols_with_missing)\n",
    "\n",
    "print(f\"Remaining features: {X_train.shape[1]}\")\n",
    "\n",
    "# Train both Random Forest and Logistic Regression models\n",
    "print(\"\\nRandom Forest:\")\n",
    "accuracy_dropping_rf, f1_dropping_rf = train_model_random_forest(X_train, X_test, y_train, y_test)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "accuracy_dropping_lr, f1_dropping_lr = train_model_logistic(X_train, X_test, y_train, y_test)\n",
    "print(\"\\nXGBoost:\")\n",
    "accuracy_dropping_xgb, f1_dropping_xgb = train_model_XGBoost(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Store the accuracies and F1-scores\n",
    "accuracies['Dropping_Columns_RF'] = accuracy_dropping_rf\n",
    "accuracies['Dropping_Columns_LR'] = accuracy_dropping_lr\n",
    "accuracies['Dropping_Columns_XGB'] = accuracy_dropping_xgb\n",
    "f1_scores['Dropping_Columns_RF'] = f1_dropping_rf\n",
    "f1_scores['Dropping_Columns_LR'] = f1_dropping_lr\n",
    "f1_scores['Dropping_Columns_XGB'] = f1_dropping_xgb\n",
    "\n",
    "# A specific data, after the procedure\n",
    "\n",
    "#print(\"\\n------------------\\n\")#X_train[(X_train['age']==58.0) & (X_train['sex']==1.0) & (X_train['dataset']==3.0) & (X_train['restecg']==0) & (X_train['exang']==2)]\n",
    "#print(\"\\nAfter Imputation: \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc0cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_and_train(X_train, y_train, X_test, y_test, strategy):\n",
    "    \"\"\"\n",
    "    Imputes missing values in the training and testing sets using the specified strategy,\n",
    "    trains both Random Forest and Logistic Regression models, and evaluates their performance.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train, y_train: Training features and labels.\n",
    "    - X_test, y_test: Testing features and labels.\n",
    "    - strategy (str): Imputation strategy to handle missing values ('mean' or 'median').\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy_rf, accuracy_lr (float): Accuracy scores of both models on the test set.\n",
    "    - X_train_imputed: Imputed training data\n",
    "    \"\"\"\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "    X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    # Train both models on the imputed training set\n",
    "    print(f\"\\n\\nImputation strategy: {strategy}\")\n",
    "    \n",
    "    print(\"Random Forest:\")\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train_imputed, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_test_imputed)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "    print(f\"Accuracy: {accuracy_rf:.4f}, F1-Score: {f1_rf:.4f}\")\n",
    "    \n",
    "    print(\"\\nLogistic Regression:\")\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(X_train_imputed, y_train)\n",
    "    y_pred_lr = lr_model.predict(X_test_imputed)\n",
    "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "    f1_lr = f1_score(y_test, y_pred_lr, average='weighted', zero_division=0)\n",
    "    print(f\"Accuracy: {accuracy_lr:.4f}, F1-Score: {f1_lr:.4f}\\n\")\n",
    "\n",
    "    print(\"\\nXGBOOST:\")\n",
    "    xgb_model = XGBClassifier()\n",
    "    xgb_model.fit(X_train_imputed, y_train)\n",
    "    y_pred_xgb = xgb_model.predict(X_test_imputed)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted', zero_division=0)\n",
    "    print(f\"Accuracy: {accuracy_xgb:.4f}, F1-Score: {f1_xgb:.4f}\\n\")\n",
    "    \n",
    "    return accuracy_rf, accuracy_lr, accuracy_xgb, f1_rf, f1_lr, f1_xgb, X_train_imputed\n",
    "\n",
    "# Use the same original split\n",
    "X_train = X_train_original.copy()\n",
    "X_test = X_test_original.copy()\n",
    "y_train = y_train_original.copy()\n",
    "y_test = y_test_original.copy()\n",
    "\n",
    "# Train the model using different imputation strategies\n",
    "strategies = ['mean', 'median']\n",
    "\n",
    "for strategy in strategies:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"METHOD: {strategy.upper()} Imputation\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    accuracy_rf, accuracy_lr, accuracy_xgb, f1_rf, f1_lr, f1_xgb, X_train_imputed = impute_and_train(X_train, y_train, X_test, y_test, strategy)\n",
    "    accuracies[f'{strategy}_RF'] = accuracy_rf\n",
    "    accuracies[f'{strategy}_LR'] = accuracy_lr\n",
    "    accuracies[f'{strategy}_XGB'] = accuracy_xgb\n",
    "    f1_scores[f'{strategy}_RF'] = f1_rf\n",
    "    f1_scores[f'{strategy}_LR'] = f1_lr\n",
    "    f1_scores[f'{strategy}_XGB'] = f1_xgb\n",
    "    \n",
    "    # A specific data, after the procedure\n",
    "    #print(\"\\n------------------\\n\")\n",
    "    #print(\"\\nAfter Imputation: \\n\")\n",
    "\n",
    "    #print(X_train_imputed[(X_train_imputed['age']==58.0) & (X_train_imputed['sex']==1.0) & (X_train_imputed['dataset']==3.0) & (X_train_imputed['chol']==385)])    print(\"\\n----------------------------\\n----------------------------\\n----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c888aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 5: KNN Imputation (k=5)\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD: KNN Imputation (k=5)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train = X_train_original.copy()\n",
    "X_test = X_test_original.copy()\n",
    "y_train = y_train_original.copy()\n",
    "y_test = y_test_original.copy()\n",
    "\n",
    "# Create combined DataFrame for imputation (KNN needs all data together)\n",
    "X_train_knn = impute_knn(X_train, n_neighbors=5)\n",
    "X_test_knn = impute_knn(X_test, n_neighbors=5)\n",
    "\n",
    "print(\"\\nXGBoost:\")\n",
    "accuracy_knn5_xgb, f1_knn5_xgb = train_model_XGBoost(X_train_knn, X_test_knn, y_train, y_test)\n",
    "print(\"\\nRandom Forest:\")\n",
    "accuracy_knn5_rf, f1_knn5_rf = train_model_random_forest(X_train_knn, X_test_knn, y_train, y_test)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "accuracy_knn5_lr, f1_knn5_lr = train_model_logistic(X_train_knn, X_test_knn, y_train, y_test)\n",
    "\n",
    "# Store the accuracies and F1-scores\n",
    "accuracies['KNN5_XGB'] = accuracy_knn5_xgb\n",
    "accuracies['KNN5_RF'] = accuracy_knn5_rf\n",
    "accuracies['KNN5_LR'] = accuracy_knn5_lr\n",
    "f1_scores['KNN5_XGB'] = f1_knn5_xgb\n",
    "f1_scores['KNN5_RF'] = f1_knn5_rf\n",
    "f1_scores['KNN5_LR'] = f1_knn5_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 6: KNN Imputation (k=10)\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD: KNN Imputation (k=10)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train = X_train_original.copy()\n",
    "X_test = X_test_original.copy()\n",
    "y_train = y_train_original.copy()\n",
    "y_test = y_test_original.copy()\n",
    "\n",
    "# Apply KNN imputation with k=10\n",
    "X_train_knn10 = impute_knn(X_train, n_neighbors=10)\n",
    "X_test_knn10 = impute_knn(X_test, n_neighbors=10)\n",
    "\n",
    "print(\"\\nXGBoost:\")\n",
    "accuracy_knn10_xgb, f1_knn10_xgb = train_model_XGBoost(X_train_knn10, X_test_knn10, y_train, y_test)\n",
    "print(\"\\nRandom Forest:\")\n",
    "accuracy_knn10_rf, f1_knn10_rf = train_model_random_forest(X_train_knn10, X_test_knn10, y_train, y_test)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "accuracy_knn10_lr, f1_knn10_lr = train_model_logistic(X_train_knn10, X_test_knn10, y_train, y_test)\n",
    "\n",
    "# Store the accuracies and F1-scores\n",
    "accuracies['KNN10_XGB'] = accuracy_knn10_xgb\n",
    "accuracies['KNN10_RF'] = accuracy_knn10_rf\n",
    "accuracies['KNN10_LR'] = accuracy_knn10_lr\n",
    "f1_scores['KNN10_XGB'] = f1_knn10_xgb\n",
    "f1_scores['KNN10_RF'] = f1_knn10_rf\n",
    "f1_scores['KNN10_LR'] = f1_knn10_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 7: MissForest Imputation\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD: MissForest Imputation (Scikit-Learn IterativeImputer)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train = X_train_original.copy()\n",
    "X_test = X_test_original.copy()\n",
    "y_train = y_train_original.copy()\n",
    "y_test = y_test_original.copy()\n",
    "\n",
    "# Create MissForest imputer using IterativeImputer with RandomForestRegressor\n",
    "missforest_imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    max_iter=40,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit on training data and transform both train and test\n",
    "missforest_imputer.fit(X_train_original)\n",
    "X_train_missforest = pd.DataFrame(\n",
    "    missforest_imputer.transform(X_train_original),\n",
    "    columns=X_train_original.columns\n",
    ")\n",
    "X_test_missforest = pd.DataFrame(\n",
    "    missforest_imputer.transform(X_test_original),\n",
    "    columns=X_test_original.columns\n",
    ")\n",
    "\n",
    "print(\"\\nXGBoost:\")\n",
    "accuracy_missforest_xgb, f1_missforest_xgb = train_model_XGBoost(X_train_missforest, X_test_missforest, y_train, y_test)\n",
    "print(\"\\nRandom Forest:\")\n",
    "accuracy_missforest_rf, f1_missforest_rf = train_model_random_forest(X_train_missforest, X_test_missforest, y_train, y_test)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "accuracy_missforest_lr, f1_missforest_lr = train_model_logistic(X_train_missforest, X_test_missforest, y_train, y_test)\n",
    "\n",
    "# Store the accuracies and F1-scores\n",
    "accuracies['MissForest_XGB'] = accuracy_missforest_xgb\n",
    "accuracies['MissForest_RF'] = accuracy_missforest_rf\n",
    "accuracies['MissForest_LR'] = accuracy_missforest_lr\n",
    "f1_scores['MissForest_XGB'] = f1_missforest_xgb\n",
    "f1_scores['MissForest_RF'] = f1_missforest_rf\n",
    "f1_scores['MissForest_LR'] = f1_missforest_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55952974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 8: MICE Imputation\n",
    "print(\"=\" * 50)\n",
    "print(\"METHOD: MICE Imputation (Scikit-Learn IterativeImputer)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "X_train = X_train_original.copy()\n",
    "X_test = X_test_original.copy()\n",
    "y_train = y_train_original.copy()\n",
    "y_test = y_test_original.copy()\n",
    "\n",
    "# Create MICE imputer using IterativeImputer with Bayesian Ridge (default for MICE)\n",
    "mice_imputer = IterativeImputer(\n",
    "    max_iter=40,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit on training data and transform both train and test\n",
    "mice_imputer.fit(X_train_original)\n",
    "X_train_mice = pd.DataFrame(\n",
    "    mice_imputer.transform(X_train_original),\n",
    "    columns=X_train_original.columns\n",
    ")\n",
    "X_test_mice = pd.DataFrame(\n",
    "    mice_imputer.transform(X_test_original),\n",
    "    columns=X_test_original.columns\n",
    ")\n",
    "\n",
    "print(\"\\nXGBoost:\")\n",
    "accuracy_mice_xgb, f1_mice_xgb = train_model_XGBoost(X_train_mice, X_test_mice, y_train, y_test)\n",
    "print(\"\\nRandom Forest:\")\n",
    "accuracy_mice_rf, f1_mice_rf = train_model_random_forest(X_train_mice, X_test_mice, y_train, y_test)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "accuracy_mice_lr, f1_mice_lr = train_model_logistic(X_train_mice, X_test_mice, y_train, y_test)\n",
    "\n",
    "# Store the accuracies and F1-scores\n",
    "accuracies['MICE_XGB'] = accuracy_mice_xgb\n",
    "accuracies['MICE_RF'] = accuracy_mice_rf\n",
    "accuracies['MICE_LR'] = accuracy_mice_lr\n",
    "f1_scores['MICE_XGB'] = f1_mice_xgb\n",
    "f1_scores['MICE_RF'] = f1_mice_rf\n",
    "f1_scores['MICE_LR'] = f1_mice_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c151a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Dictionary to DataFrame and format results\n",
    "# Create separate dataframes for accuracy and F1-score\n",
    "\n",
    "# Ensure accuracies and f1_scores are dictionaries (in case kernel was reset)\n",
    "if not isinstance(accuracies, dict) or not isinstance(f1_scores, dict):\n",
    "    print(\"WARNING: Dictionaries were corrupted. Please re-run cells 10-18 to rebuild results.\")\n",
    "else:\n",
    "    results_accuracy = []\n",
    "    results_f1 = []\n",
    "\n",
    "    # Process accuracies and F1-scores together using the SAME method keys\n",
    "    for method, accuracy in accuracies.items():\n",
    "        if '_XGB' in method:\n",
    "            imputation_method = method.replace('_XGB', '')\n",
    "            classifier = 'XGBoost'\n",
    "        elif '_RF' in method:\n",
    "            imputation_method = method.replace('_RF', '')\n",
    "            classifier = 'RandomForest'\n",
    "        elif '_LR' in method:\n",
    "            imputation_method = method.replace('_LR', '')\n",
    "            classifier = 'LogisticRegression'\n",
    "        else:\n",
    "            imputation_method = method\n",
    "            classifier = 'XGBoost'\n",
    "        \n",
    "        results_accuracy.append({\n",
    "            'Imputation Method': imputation_method,\n",
    "            'Classifier': classifier,\n",
    "            'Accuracy': round(accuracy, 4)\n",
    "        })\n",
    "        \n",
    "        # Get F1-score using the EXACT same key (method) that's in accuracies\n",
    "        if method in f1_scores:\n",
    "            f1_value = f1_scores[method]\n",
    "            results_f1.append({\n",
    "                'Imputation Method': imputation_method,\n",
    "                'Classifier': classifier,\n",
    "                'F1-Score': round(f1_value, 4)\n",
    "            })\n",
    "\n",
    "    df_accuracy = pd.DataFrame(results_accuracy)\n",
    "    df_f1 = pd.DataFrame(results_f1)\n",
    "\n",
    "    # Print total entries to verify all methods are captured\n",
    "    print(\"\\nDebug Info:\")\n",
    "    print(f\"Total accuracy entries: {len(results_accuracy)}\")\n",
    "    print(f\"Total F1-score entries: {len(results_f1)}\")\n",
    "    print(f\"Accuracy method keys: {list(accuracies.keys())}\")\n",
    "    print(f\"F1-score method keys: {list(f1_scores.keys())}\")\n",
    "\n",
    "    # Pivot to show side-by-side comparison\n",
    "    if not df_accuracy.empty:\n",
    "        df_accuracy_pivot = df_accuracy.pivot(index='Imputation Method', columns='Classifier', values='Accuracy')\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"RESULTS: Accuracy Comparison (All Methods)\")\n",
    "        print(\"=\"*70)\n",
    "        print(df_accuracy_pivot)\n",
    "\n",
    "    if not df_f1.empty:\n",
    "        df_f1_pivot = df_f1.pivot(index='Imputation Method', columns='Classifier', values='F1-Score')\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"RESULTS: F1-Score Comparison (All Methods)\")\n",
    "        print(\"=\"*70)\n",
    "        print(df_f1_pivot)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\nNote: F1-Score is more reliable for imbalanced multi-class data\")\n",
    "    print(\"Lower values may indicate class imbalance issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a3a8e",
   "metadata": {},
   "source": [
    "# Optimization Notes: Why MICE/MissForest May Not Be Much Better\n",
    "\n",
    "## Why Complex Methods Don't Always Win\n",
    "\n",
    "For this dataset, **it's normal** that MICE and MissForest don't dramatically outperform mean/median. Here's why:\n",
    "\n",
    "### Dataset Characteristics:\n",
    "- **Small dataset**: 920 samples Ã— 14 features (complex methods need more data)\n",
    "- **Low missing rate**: ~5-7% missing (imputation quality differences are small)\n",
    "- **Simple patterns**: Missing values are likely MCAR, not complex MNAR patterns\n",
    "\n",
    "### Parameters We Optimized:\n",
    "\n",
    "**MissForest:**\n",
    "- `n_estimators=200` (up from 100) - More trees = better quality\n",
    "- `max_iter=40` (up from 30) - More iterations = more refinement\n",
    "\n",
    "**MICE:**\n",
    "- `max_iter=40` (up from 30) - More iterations for convergence\n",
    "- `sample_posterior=False` (changed from True) - Better stability on small datasets\n",
    "- `n_imputations=5` - Multiple imputations increase robustness\n",
    "\n",
    "### When Advanced Methods Excel:\n",
    "Advanced methods like MICE/MissForest typically show ~5-15% improvement over simple methods when:\n",
    "1. **Missing data is large** (20%+) and **MNAR** (Not Missing At Random)\n",
    "2. **Dataset is large** (10K+ samples) with **complex relationships**\n",
    "3. **Missing patterns depend on other variables** (e.g., people with low income less likely to report salary)\n",
    "\n",
    "### Recommendation:\n",
    "Given your results, **mean/median imputation is efficient for this dataset**. The computational cost of MICE/MissForest (~10-20x slower) may not justify the gains. However, keep the advanced methods for comparison and documentation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed58cd6",
   "metadata": {},
   "source": [
    "## Why is accuracy 0.5?\n",
    "\n",
    "### Findings:\n",
    "1. **Multi-class classification problem** (not binary!)\n",
    "   - Target variable has 5 classes: 0, 1, 2, 3, 4\n",
    "   - Classes are imbalanced:\n",
    "     - Class 0: 45.7%\n",
    "     - Class 1: 28.7%\n",
    "     - Class 2: 11.4%\n",
    "     - Class 3: 11.0%\n",
    "     - Class 4: 3.3%\n",
    "\n",
    "2. **Accuracy of 0.5-0.6 is actually reasonable** for imbalanced multi-class:\n",
    "   - Random guessing would be 20% (1/5 classes)\n",
    "   - Predicting majority class: 45.7%\n",
    "   - **Your model at 59.8% is doing better than baseline!**\n",
    "\n",
    "3. **F1-Score is more reliable** than accuracy for imbalanced data\n",
    "   - F1-Score weights precision and recall\n",
    "   - Better metric for comparing imputation methods\n",
    "\n",
    "### Why are F1-Scores lower than accuracy?\n",
    "- Weighted F1 considers class imbalance\n",
    "- Shows true performance across all classes\n",
    "- MissForest and MICE may perform worse due to:\n",
    "  - Over-fitting during iterative imputation\n",
    "  - Introducing artificial patterns\n",
    "  - Data distribution shifts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2eaa25",
   "metadata": {},
   "source": [
    "# Part 2: Artificial Missing Data Experiment\n",
    "\n",
    "Now we'll evaluate imputation quality by:\n",
    "1. Creating a complete dataset (removing rows with real missing values)\n",
    "2. Artificially introducing 25% missing values\n",
    "3. Applying different imputation methods\n",
    "4. Comparing results using Mean Squared Error (MSE) - lower is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafe4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Use the SAME complete rows from Part 1 Pairwise Deletion\n",
    "# This ensures we're comparing apples to apples\n",
    "print(\"=\" * 70)\n",
    "print(\"Using same 308 complete rows as Part 1 Pairwise Deletion\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get the complete rows by filtering the original data\n",
    "df_original_full = read_data()\n",
    "complete_mask = df_original_full.notna().all(axis=1)\n",
    "df_complete = df_original_full[complete_mask].copy()\n",
    "\n",
    "print(f\"\\nComplete dataset shape: {df_complete.shape}\")\n",
    "print(f\"Missing values in complete dataset: {df_complete.isnull().sum().sum()}\")\n",
    "\n",
    "# Now split this complete dataset using the SAME indices as Part 1\n",
    "# We need to identify which rows from df_complete correspond to the train/test split\n",
    "# We'll use the same split strategy: split first, then we have the complete subset\n",
    "\n",
    "# To match Part 1 exactly, we need to:\n",
    "# 1. Split ALL data first (like Part 1 does)\n",
    "# 2. Then filter to complete rows only\n",
    "# 3. This gives us the exact same train/test split as Pairwise Deletion in Part 1\n",
    "\n",
    "df_temp = read_data()\n",
    "X_temp = df_temp.drop('num', axis=1)\n",
    "y_temp = df_temp['num']\n",
    "X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Now filter to complete rows only (matching Pairwise deletion logic)\n",
    "train_mask = X_train_temp.notna().all(axis=1)\n",
    "X_train_indices = X_train_temp[train_mask].index\n",
    "y_train_indices = y_train_temp[train_mask].index\n",
    "\n",
    "test_mask = X_test_temp.notna().all(axis=1)\n",
    "X_test_indices = X_test_temp[test_mask].index\n",
    "y_test_indices = y_test_temp[test_mask].index\n",
    "\n",
    "# Now create df_complete with a marker for train/test split\n",
    "df_complete['split'] = 'unused'\n",
    "df_complete.loc[df_complete.index.isin(X_train_indices), 'split'] = 'train'\n",
    "df_complete.loc[df_complete.index.isin(X_test_indices), 'split'] = 'test'\n",
    "\n",
    "# Remove the rows that weren't in the original split (shouldn't be any, but just in case)\n",
    "df_complete = df_complete[df_complete['split'].isin(['train', 'test'])].copy()\n",
    "\n",
    "print(f\"Train rows: {(df_complete['split'] == 'train').sum()}\")\n",
    "print(f\"Test rows: {(df_complete['split'] == 'test').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Artificially introduce 25% missing values in numerical columns\n",
    "# Using the same complete data with the same train/test split\n",
    "np.random.seed(42)\n",
    "missing_fraction = 0.25\n",
    "\n",
    "# Create copy for artificial missingness (excluding the 'split' column)\n",
    "df_artificial = df_complete.copy()\n",
    "\n",
    "# Store original values and positions where we'll introduce missing data\n",
    "original_values = {}\n",
    "missing_positions = {}\n",
    "\n",
    "# Get numerical columns (exclude target variable 'num' and 'split' marker)\n",
    "numerical_cols = df_artificial.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['num', 'split']]\n",
    "\n",
    "print(f\"\\nIntroducing {missing_fraction*100}% missing values in {len(numerical_cols)} numerical columns...\")\n",
    "print(f\"Numerical columns: {numerical_cols}\\n\")\n",
    "\n",
    "for col in numerical_cols:\n",
    "    n_missing = int(len(df_artificial) * missing_fraction)\n",
    "    missing_idx = np.random.choice(df_artificial.index, size=n_missing, replace=False)\n",
    "    \n",
    "    # Store original values before introducing missing data\n",
    "    original_values[col] = df_artificial.loc[missing_idx, col].copy()\n",
    "    missing_positions[col] = missing_idx\n",
    "    \n",
    "    # Introduce missing values\n",
    "    df_artificial.loc[missing_idx, col] = np.nan\n",
    "\n",
    "print(f\"Total missing values introduced: {df_artificial.isnull().sum().sum()}\")\n",
    "print(f\"Percentage of dataset now missing: {(df_artificial.isnull().sum().sum() / (df_artificial.shape[0] * df_artificial.shape[1]) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305102fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define function to calculate MSE for imputation quality\n",
    "def calculate_mse(original_values_dict, imputed_df, missing_positions_dict):\n",
    "    \"\"\"\n",
    "    Calculate Mean Squared Error between original values and imputed values.\n",
    "    \n",
    "    Parameters:\n",
    "    - original_values_dict: dict with column -> original values (Series)\n",
    "    - imputed_df: DataFrame with imputed values\n",
    "    - missing_positions_dict: dict with column -> indices where values were removed\n",
    "    \n",
    "    Returns:\n",
    "    - mse: Mean Squared Error across all imputed values\n",
    "    \"\"\"\n",
    "    all_original = []\n",
    "    all_imputed = []\n",
    "    \n",
    "    for col in original_values_dict.keys():\n",
    "        orig_vals = original_values_dict[col].values\n",
    "        imputed_vals = imputed_df.loc[missing_positions_dict[col], col].values\n",
    "        \n",
    "        all_original.extend(orig_vals)\n",
    "        all_imputed.extend(imputed_vals)\n",
    "    \n",
    "    mse = mean_squared_error(all_original, all_imputed)\n",
    "    return mse\n",
    "\n",
    "print(\"MSE calculation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Apply imputation methods and calculate MSE for each\n",
    "mse_results = {}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUATING IMPUTATION QUALITY WITH MSE (Lower is Better)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Method 1: Mean Imputation\n",
    "print(\"\\n1. Mean Imputation\")\n",
    "df_mean = df_artificial.copy()\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "df_mean[numerical_cols] = imputer_mean.fit_transform(df_mean[numerical_cols])\n",
    "mse_mean = calculate_mse(original_values, df_mean, missing_positions)\n",
    "mse_results['Mean'] = mse_mean\n",
    "print(f\"   MSE: {mse_mean:.4f}\")\n",
    "\n",
    "# Method 2: Median Imputation\n",
    "print(\"\\n2. Median Imputation\")\n",
    "df_median = df_artificial.copy()\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "df_median[numerical_cols] = imputer_median.fit_transform(df_median[numerical_cols])\n",
    "mse_median = calculate_mse(original_values, df_median, missing_positions)\n",
    "mse_results['Median'] = mse_median\n",
    "print(f\"   MSE: {mse_median:.4f}\")\n",
    "\n",
    "# Method 3: KNN Imputation (k=5)\n",
    "print(\"\\n3. KNN Imputation (k=5)\")\n",
    "df_knn5 = df_artificial.copy()\n",
    "imputer_knn5 = KNNImputer(n_neighbors=5)\n",
    "df_knn5[numerical_cols] = imputer_knn5.fit_transform(df_knn5[numerical_cols])\n",
    "mse_knn5 = calculate_mse(original_values, df_knn5, missing_positions)\n",
    "mse_results['KNN (k=5)'] = mse_knn5\n",
    "print(f\"   MSE: {mse_knn5:.4f}\")\n",
    "\n",
    "# Method 4: KNN Imputation (k=10)\n",
    "print(\"\\n4. KNN Imputation (k=10)\")\n",
    "df_knn10 = df_artificial.copy()\n",
    "imputer_knn10 = KNNImputer(n_neighbors=10)\n",
    "df_knn10[numerical_cols] = imputer_knn10.fit_transform(df_knn10[numerical_cols])\n",
    "mse_knn10 = calculate_mse(original_values, df_knn10, missing_positions)\n",
    "mse_results['KNN (k=10)'] = mse_knn10\n",
    "print(f\"   MSE: {mse_knn10:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2246654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 5: MissForest Imputation\n",
    "print(\"\\n5. MissForest Imputation\")\n",
    "df_missforest_eval = df_artificial.copy()\n",
    "df_missforest_eval = impute_missForest(df_missforest_eval)\n",
    "mse_missforest = calculate_mse(original_values, df_missforest_eval, missing_positions)\n",
    "mse_results['MissForest'] = mse_missforest\n",
    "print(f\"   MSE: {mse_missforest:.4f}\")\n",
    "\n",
    "# Method 6: MICE Imputation\n",
    "print(\"\\n6. MICE Imputation (5 imputations)\")\n",
    "df_artificial_mice = df_artificial.copy()\n",
    "mice_imputations_eval = impute_mice(df_artificial_mice, n_imputations=5, max_iter=40)\n",
    "df_mice_eval = pool_mice_results(mice_imputations_eval)\n",
    "mse_mice = calculate_mse(original_values, df_mice_eval, missing_positions)\n",
    "mse_results['MICE'] = mse_mice\n",
    "print(f\"   MSE: {mse_mice:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Display MSE comparison results\n",
    "mse_df = pd.DataFrame(list(mse_results.items()), columns=['Imputation Method', 'MSE'])\n",
    "mse_df = mse_df.sort_values('MSE')\n",
    "mse_df['MSE'] = mse_df['MSE'].round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MSE COMPARISON RESULTS (Lower is Better)\")\n",
    "print(\"=\" * 60)\n",
    "mse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1b681",
   "metadata": {},
   "source": [
    "## Now let's compare prediction accuracy\n",
    "\n",
    "We'll train RandomForest on:\n",
    "1. The real complete dataset (baseline)\n",
    "2. Each imputed dataset\n",
    "\n",
    "This will show if lower MSE (better imputation) leads to higher prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7feff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the SAME train/test split from Part 1 (already done on the full 920 rows)\n",
    "# Filter to get only the complete rows from that split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dictionary to store accuracy results\n",
    "accuracy_results = {}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING RANDOM FOREST ON DIFFERENT DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Baseline: Train on real complete data using the SAME split as Part 1\n",
    "print(\"\\n1. Baseline - Real Complete Data (No Missing Values)\")\n",
    "\n",
    "# Use the original split indices, but filter to only complete rows\n",
    "# This matches what Pairwise Deletion does in Part 1\n",
    "X_train_baseline = X_train_original.copy()\n",
    "X_test_baseline = X_test_original.copy()\n",
    "y_train_baseline = y_train_original.copy()\n",
    "y_test_baseline = y_test_original.copy()\n",
    "\n",
    "# Filter to complete rows only (same as Pairwise Deletion)\n",
    "train_mask = X_train_baseline.notna().all(axis=1)\n",
    "X_train_baseline = X_train_baseline[train_mask]\n",
    "y_train_baseline = y_train_baseline[train_mask]\n",
    "\n",
    "test_mask = X_test_baseline.notna().all(axis=1)\n",
    "X_test_baseline = X_test_baseline[test_mask]\n",
    "y_test_baseline = y_test_baseline[test_mask]\n",
    "\n",
    "print(f\"   Train size: {X_train_baseline.shape[0]}, Test size: {X_test_baseline.shape[0]}\")\n",
    "\n",
    "rf_baseline = RandomForestClassifier(random_state=42)\n",
    "rf_baseline.fit(X_train_baseline, y_train_baseline)\n",
    "y_pred_baseline = rf_baseline.predict(X_test_baseline)\n",
    "acc_baseline = accuracy_score(y_test_baseline, y_pred_baseline)\n",
    "accuracy_results['Baseline (Real Data)'] = acc_baseline\n",
    "print(f\"   Accuracy: {acc_baseline:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For imputed datasets, we need to:\n",
    "# 1. Map the 308 complete row indices back to train/test split\n",
    "# 2. Use the SAME train/test division as Part 1\n",
    "\n",
    "# Get the indices of complete rows in original data\n",
    "complete_indices = df_complete.index\n",
    "\n",
    "# Find which complete rows were in train vs test in the original split\n",
    "train_complete_indices = [idx for idx in X_train_original.index if idx in complete_indices]\n",
    "test_complete_indices = [idx for idx in X_test_original.index if idx in complete_indices]\n",
    "\n",
    "print(f\"\\nUsing original split: {len(train_complete_indices)} train + {len(test_complete_indices)} test = {len(complete_indices)} total complete rows\")\n",
    "\n",
    "# 2. Train on Mean Imputed data\n",
    "print(\"\\n2. Mean Imputation\")\n",
    "X_train_mean = df_mean.drop(['num', 'split'], axis=1).loc[train_complete_indices]\n",
    "y_train_mean = df_mean['num'].loc[train_complete_indices]\n",
    "X_test_mean = df_mean.drop(['num', 'split'], axis=1).loc[test_complete_indices]\n",
    "y_test_mean = df_mean['num'].loc[test_complete_indices]\n",
    "\n",
    "rf_mean = RandomForestClassifier(random_state=42)\n",
    "rf_mean.fit(X_train_mean, y_train_mean)\n",
    "y_pred_mean = rf_mean.predict(X_test_mean)\n",
    "acc_mean = accuracy_score(y_test_mean, y_pred_mean)\n",
    "accuracy_results['Mean'] = acc_mean\n",
    "print(f\"   MSE: {mse_results['Mean']:.4f}\")\n",
    "print(f\"   Accuracy: {acc_mean:.4f}\")\n",
    "\n",
    "# 3. Train on Median Imputed data\n",
    "print(\"\\n3. Median Imputation\")\n",
    "X_train_median = df_median.drop(['num', 'split'], axis=1).loc[train_complete_indices]\n",
    "y_train_median = df_median['num'].loc[train_complete_indices]\n",
    "X_test_median = df_median.drop(['num', 'split'], axis=1).loc[test_complete_indices]\n",
    "y_test_median = df_median['num'].loc[test_complete_indices]\n",
    "\n",
    "rf_median = RandomForestClassifier(random_state=42)\n",
    "rf_median.fit(X_train_median, y_train_median)\n",
    "y_pred_median = rf_median.predict(X_test_median)\n",
    "acc_median = accuracy_score(y_test_median, y_pred_median)\n",
    "accuracy_results['Median'] = acc_median\n",
    "print(f\"   MSE: {mse_results['Median']:.4f}\")\n",
    "print(f\"   Accuracy: {acc_median:.4f}\")\n",
    "\n",
    "# 4. Train on KNN (k=5) Imputed data\n",
    "print(\"\\n4. KNN Imputation (k=5)\")\n",
    "X_train_knn5 = df_knn5.drop(['num', 'split'], axis=1).loc[train_complete_indices]\n",
    "y_train_knn5 = df_knn5['num'].loc[train_complete_indices]\n",
    "X_test_knn5 = df_knn5.drop(['num', 'split'], axis=1).loc[test_complete_indices]\n",
    "y_test_knn5 = df_knn5['num'].loc[test_complete_indices]\n",
    "\n",
    "rf_knn5 = RandomForestClassifier(random_state=42)\n",
    "rf_knn5.fit(X_train_knn5, y_train_knn5)\n",
    "y_pred_knn5 = rf_knn5.predict(X_test_knn5)\n",
    "acc_knn5 = accuracy_score(y_test_knn5, y_pred_knn5)\n",
    "accuracy_results['KNN (k=5)'] = acc_knn5\n",
    "print(f\"   MSE: {mse_results['KNN (k=5)']:.4f}\")\n",
    "print(f\"   Accuracy: {acc_knn5:.4f}\")\n",
    "\n",
    "# 5. Train on KNN (k=10) Imputed data\n",
    "print(\"\\n5. KNN Imputation (k=10)\")\n",
    "X_train_knn10 = df_knn10.drop(['num', 'split'], axis=1).loc[train_complete_indices]\n",
    "y_train_knn10 = df_knn10['num'].loc[train_complete_indices]\n",
    "X_test_knn10 = df_knn10.drop(['num', 'split'], axis=1).loc[test_complete_indices]\n",
    "y_test_knn10 = df_knn10['num'].loc[test_complete_indices]\n",
    "\n",
    "rf_knn10 = RandomForestClassifier(random_state=42)\n",
    "rf_knn10.fit(X_train_knn10, y_train_knn10)\n",
    "y_pred_knn10 = rf_knn10.predict(X_test_knn10)\n",
    "acc_knn10 = accuracy_score(y_test_knn10, y_pred_knn10)\n",
    "accuracy_results['KNN (k=10)'] = acc_knn10\n",
    "print(f\"   MSE: {mse_results['KNN (k=10)']:.4f}\")\n",
    "print(f\"   Accuracy: {acc_knn10:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db7bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Train on MissForest Imputed data\n",
    "print(\"\\n6. MissForest Imputation\")\n",
    "X_train_missforest_eval = df_missforest_eval.drop(['num', 'split'], axis=1).loc[train_complete_indices]\n",
    "y_train_missforest_eval = df_missforest_eval['num'].loc[train_complete_indices]\n",
    "X_test_missforest_eval = df_missforest_eval.drop(['num', 'split'], axis=1).loc[test_complete_indices]\n",
    "y_test_missforest_eval = df_missforest_eval['num'].loc[test_complete_indices]\n",
    "\n",
    "rf_missforest = RandomForestClassifier(random_state=42)\n",
    "rf_missforest.fit(X_train_missforest_eval, y_train_missforest_eval)\n",
    "y_pred_missforest = rf_missforest.predict(X_test_missforest_eval)\n",
    "acc_missforest = accuracy_score(y_test_missforest_eval, y_pred_missforest)\n",
    "accuracy_results['MissForest'] = acc_missforest\n",
    "print(f\"   MSE: {mse_results['MissForest']:.4f}\")\n",
    "print(f\"   Accuracy: {acc_missforest:.4f}\")\n",
    "\n",
    "# 7. Train on MICE Imputed data\n",
    "print(\"\\n7. MICE Imputation (5 imputations)\")\n",
    "X_train_mice_eval = df_mice_eval.drop(['num', 'split'], axis=1).loc[train_complete_indices]\n",
    "y_train_mice_eval = df_mice_eval['num'].loc[train_complete_indices]\n",
    "X_test_mice_eval = df_mice_eval.drop(['num', 'split'], axis=1).loc[test_complete_indices]\n",
    "y_test_mice_eval = df_mice_eval['num'].loc[test_complete_indices]\n",
    "\n",
    "rf_mice = RandomForestClassifier(random_state=42)\n",
    "rf_mice.fit(X_train_mice_eval, y_train_mice_eval)\n",
    "y_pred_mice = rf_mice.predict(X_test_mice_eval)\n",
    "acc_mice = accuracy_score(y_test_mice_eval, y_pred_mice)\n",
    "accuracy_results['MICE'] = acc_mice\n",
    "print(f\"   MSE: {mse_results['MICE']:.4f}\")\n",
    "print(f\"   Accuracy: {acc_mice:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison table\n",
    "comparison_data = []\n",
    "\n",
    "# Add baseline (no MSE since it's real data)\n",
    "comparison_data.append({\n",
    "    'Method': 'Baseline (Real Data)',\n",
    "    'MSE': 'N/A',\n",
    "    'Accuracy': accuracy_results['Baseline (Real Data)']\n",
    "})\n",
    "\n",
    "# Add imputation methods\n",
    "for method in ['Mean', 'Median', 'KNN (k=5)', 'KNN (k=10)', 'MissForest', 'MICE']:\n",
    "    comparison_data.append({\n",
    "        'Method': method,\n",
    "        'MSE': mse_results[method],\n",
    "        'Accuracy': accuracy_results[method]\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df['Accuracy'] = comparison_df['Accuracy'].apply(lambda x: round(x, 4))\n",
    "comparison_df['MSE'] = comparison_df['MSE'].apply(lambda x: round(x, 4) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Sort by accuracy (descending)\n",
    "comparison_df_sorted = comparison_df.copy()\n",
    "comparison_df_sorted['Accuracy_num'] = comparison_df_sorted['Accuracy']\n",
    "comparison_df_sorted = comparison_df_sorted.sort_values('Accuracy_num', ascending=False)\n",
    "comparison_df_sorted = comparison_df_sorted.drop('Accuracy_num', axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL COMPARISON: MSE vs Prediction Accuracy\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSorted by Accuracy (Higher is Better):\")\n",
    "comparison_df_sorted\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
